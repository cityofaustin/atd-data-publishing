"""
Parse COA traffic report feed and upload to postgREST database.

This feed is generated by some CTM black magic that extracts incident data from the public safety CAD databse and publishes it in the form of an RSS feed and cold fusion-powered HTML table.
See: http://www.ci.austin.tx.us/qact/qact_rss.cfm

"""
import arrow
import feedparser
import requests

import _setpath
from config.secrets import *
from config.postgrest.config import TRAFFIC_REPORT_SCRAPER as config


def query(url, method, data=None, auth=JOB_DB_API_TOKEN):

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {auth}",
        "Prefer": "return=representation, resolution=merge-duplicates",
    }

    if method.upper() == "SELECT":
        res = requests.get(url, headers=headers)

    elif method.upper() == "UPSERT":
        res = requests.post(url, headers=headers, json=data)

    elif method.upper() == "DELETE":
        res = requests.delete(url, headers=headers)

    else:
        raise Exception("Unknown method requested.")

    res.raise_for_status()
    return res.json()


def eq_filter(url, field_name, field_val):
    """Summary
    
    Args:
        url (TYPE): Description
        field_name (TYPE): Description
        field_val (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    return f"{url}?{field_name}=eq.{field_val}"


def in_filter(url, field_name, val_list):
    """Summary
    
    Args:
        url (TYPE): Description
        field_name (TYPE): Description
        val_list (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    vals = ",".join(val_list)
    return f"{url}?{field_name}=in.({vals})"


def parse_feed(feed, config):
    """
    Extract feed data by applying some unfortunate hardcoded parsing logic to feed entries
    
    Args:
        feed (TYPE): Description
        config (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    records = []
    for entry in feed.entries:
        record = handle_record(entry, config)
        records.append(record)
    return records


def parse_title(title):
    """Summary
    
    Args:
        title (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    #  Aassume feed will never have Euro sign (it is non-ascii)
    #  TODO: use regex
    title = title.replace("    ", "€")

    #  remove remaining whitespace clumps like so:
    title = " ".join(title.split())

    #  split into list on
    title = title.split("€")

    #  remove empty strings. reducing to two elements
    title = [elem for elem in title if elem]

    issue = title[1].replace("-", "").strip()
    address = title[0].replace("/", "&")

    return address, issue


def extract_geocode(summary):
    """Summary
    
    Args:
        summary (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    elements = summary.split("|")
    elements = [elem.strip() for elem in elements]
    return elements[1:3]


def handle_record(entry, config):
    """Summary
    
    Args:
        entry (TYPE): Description
        config (TYPE): Description
    
    Returns:
        TYPE: Description
    """
    #  turn rss feed entry into traffic report dict
    record = {}
    published_date = arrow.get(entry.published_parsed).replace(tzinfo="US/Central")
    status_date = arrow.now().format()

    #  compose record id from entry identifier (which is not wholly unique) and
    #  publication timestamp
    record_id = "{}_{}".format(entry.id, published_date.timestamp)
    record[config["primary_key"]] = record_id
    record[config["date_field"]] = published_date.format()
    record[config["status_field"]] = "ACTIVE"
    record[config["status_date_field"]] = status_date
    title = entry.title
    title = parse_title(title)
    record["address"] = title[0]
    record["issue_reported"] = title[1]
    geocode = extract_geocode(entry.summary)
    record["latitude"] = geocode[0]
    record["longitude"] = geocode[1]
    return record


def apply_status(records, field="traffic_report_status", status="ARCHIVED"):
    """Summary
    
    Args:
        records (TYPE): Description
        field (str, optional): Description
        status (str, optional): Description
    
    Returns:
        TYPE: Description
    """
    for record in records:
        record[field] = status
    return records


def timestamp(records, field="traffic_report_status_date_time"):
    """Summary
    
    Args:
        records (TYPE): Description
        field (str, optional): Description
    
    Returns:
        TYPE: Description
    """
    for record in records:
        record[field] = arrow.now().format()
    return records


def main():

    active_records_endpoint = eq_filter(
        config["endpoint"], config["status_field"], "ACTIVE"
    )

    active_records = query(active_records_endpoint, "select")

    active_records_ids = [record[config["primary_key"]] for record in active_records]

    feed = feedparser.parse(config["feed_url"])
    feed_records = parse_feed(feed, config)
    feed_record_ids = [record[config["primary_key"]] for record in feed_records]

    new_records = [
        record
        for record in feed_records
        if record[config["primary_key"]] not in active_records_ids
    ]

    archive_records = [
        record
        for record in active_records
        if record[config["primary_key"]] not in feed_record_ids
    ]

    archive_records = apply_status(archive_records, field=config["status_field"])
    archive_records = timestamp(archive_records, field=config["status_date_field"])

    payload = new_records + archive_records

    if payload:
        res = query(config["endpoint"], "UPSERT", data=payload)

    return len(payload)


if __name__ == "__main__":
    main()
